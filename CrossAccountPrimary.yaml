AWSTemplateFormatVersion: '2010-09-09'
Description: Cross account primary stack.
Parameters:
  DeploymentOrgPath:
    Type: String
Resources:
  # This KMS key is for use with the cross account build/deploment.
  # The permermissions allow the CrossAccountCodePipeline role within the deployment
  # organization to use the key.
  KMSKey:
    Type: 'AWS::KMS::Key'
    Properties:
      Description: Used by Assumed Roles in deploy accounts to Encrypt/Decrypt code
      EnableKeyRotation: true
      KeyPolicy:
        Version: '2012-10-17'
        Id: !Ref 'AWS::StackName'
        Statement:
          - Sid: Allows admin of the key
            Effect: Allow
            Principal:
              AWS: !Sub 'arn:aws:iam::${AWS::AccountId}:root'
            Action:
              - 'kms:Create*'
              - 'kms:Describe*'
              - 'kms:Enable*'
              - 'kms:List*'
              - 'kms:Put*'
              - 'kms:Update*'
              - 'kms:Revoke*'
              - 'kms:Disable*'
              - 'kms:Get*'
              - 'kms:Delete*'
              - 'kms:ScheduleKeyDeletion'
              - 'kms:CancelKeyDeletion'
              - 'kms:Encrypt'
              - 'kms:Decrypt'
              - 'kms:ReEncrypt*'
              - 'kms:GenerateDataKey*'
              - 'kms:DescribeKey'
            Resource: '*'
          - Effect: Allow
            Principal: '*'
            Action:
              - 'kms:Encrypt'
              - 'kms:Decrypt'
              - 'kms:ReEncrypt*'
              - 'kms:GenerateDataKey*'
              - 'kms:DescribeKey'
            Resource: '*'
            Condition:
              ArnLike:
                aws:PrincipalArn: arn:aws:iam::*:role/CrossAccountCodePipeline
              ForAnyValue:StringLike:
                aws:PrincipalOrgPaths:
                  - !Ref DeploymentOrgPath

  KMSAlias:
    Type: 'AWS::KMS::Alias'
    Properties:
      AliasName: alias/codepipeline-crossaccounts
      TargetKeyId: !Ref KMSKey

  # Topic to be used for manual intervention notification in a pipeline.
  ManualInterventionTopic:
    Type: 'AWS::SNS::Topic'
    Properties:
      DisplayName: Topic for pipeline manual intervention notifications
      TopicName: PipelineManualIntervention

  # Role for the sync artifacts function.
  SyncArtifactsRole:
    Type: 'AWS::IAM::Role'
    Properties:
      RoleName: CrossAccountPipelineSyncArtifacts
      AssumeRolePolicyDocument:
        Version: '2012-10-17'
        Statement:
          - Effect: Allow
            Principal:
              Service: lambda.amazonaws.com
            Action: 'sts:AssumeRole'
      ManagedPolicyArns:
        - !Ref SyncArtifactsPolicy
        - 'arn:aws:iam::aws:policy/service-role/AWSLambdaBasicExecutionRole'

  # This policy gives the sync artifacts function permission to decrypt with KMS key
  # and to send updates to CodePipeline.
  SyncArtifactsPolicy:
    Type: 'AWS::IAM::ManagedPolicy'
    Properties:
      ManagedPolicyName: CrossAccountPipelineSyncArtifacts
      Description: Policy for syncing artifact data for cross account pipelines
      PolicyDocument:
        Version: '2012-10-17'
        Statement:
          - Action:
              - 'kms:Decrypt'
            Effect: Allow
            Resource:
              - !GetAtt KMSKey.Arn
          - Action:
              - 'codepipeline:*' # pretty sure this doesn't need to be star.
            Effect: Allow
            Resource: '*'

  # This function takes the artifacts supplied to it and makes sure they are
  # available in the requested region. This function should be called from
  # CodePipeline. The CodePipeline step should include all the input artifacts
  # that will be needed in the destination region.
  SyncArtifactsFunction:
    Type: 'AWS::Lambda::Function'
    Properties:
      Code:
        ZipFile:
          'Fn::Join':
            - |+

            - - const aws = require('aws-sdk');
              - "const s3 = new aws.S3({region: 'us-east-1'});"
              - const codepipeline = new aws.CodePipeline();
              - const path = require('path');
              - ''
              - 'exports.handler = function main(event, context) {'
              - '  console.log(JSON.stringify(event));'
              - '  // Retrieve the Job ID from the Lambda action'
              - '  let jobId = event["CodePipeline.job"].id;'
              - '  try {'
              - '    let data = JSON.parse(event["CodePipeline.job"].data.actionConfiguration.configuration.UserParameters);'
              - '    let destBucket = data.DestinationBucket;'
              - '  '
              - '    // Make a task for each combination of record and destBucket'
              - '    let tasks = [];'
              - '  '
              - '    for (var i = 0; i < event["CodePipeline.job"].data.inputArtifacts.length; i++) {'
              - '      const sourceBucket = event["CodePipeline.job"].data.inputArtifacts[i].location.s3Location.bucketName;'
              - '      const sourceKey = event["CodePipeline.job"].data.inputArtifacts[i].location.s3Location.objectKey;'
              - '  '
              - '      if (sourceBucket != destBucket)'
              - '        tasks.push(replicatePromise(sourceBucket, sourceKey.replace(/\+/g, " "), destBucket));'
              - '      }'
              - '  '
              - '    if (tasks.length != 0) {'
              - '      Promise.all(tasks)'
              - '        .then(() => {'
              - "          putJobSuccess(jobId, 'Successfully synced artifacts', context);"
              - '        })'
              - '        .catch((e) => {'
              - '          putJobFailure(jobId, e, context);'
              - '        });'
              - '    } else {'
              - "      putJobSuccess(jobId, 'No need to sync', context);"
              - '    }'
              - '  }'
              - '  catch(ex) {'
              - '    putJobFailure(jobId, ex, context);'
              - '  }'
              - '};'
              - ''
              - ' // Notify AWS CodePipeline of a successful job'
              - 'function putJobSuccess(jobId, message, context) {'
              - '  var params = {'
              - '    jobId: jobId'
              - '  };'
              - '  codepipeline.putJobSuccessResult(params, function(err, data) {'
              - '    if(err) {'
              - '      context.fail(err);'
              - '    }'
              - '    else {'
              - '      context.succeed(message);'
              - '    }'
              - '  });'
              - '};'
              - ''
              - // Notify AWS CodePipeline of a failed job
              - 'function putJobFailure(jobId, message, context) {'
              - '  var params = {'
              - '    jobId: jobId,'
              - '    failureDetails: {'
              - '      message: JSON.stringify(message),'
              - "      type: 'JobFailed',"
              - '      externalExecutionId: context.invokeid'
              - '    }'
              - '  };'
              - '  codepipeline.putJobFailureResult(params, function(err, data) {'
              - '    context.fail(message);'
              - '  });'
              - '};'
              - ''
              - 'function replicatePromise(sourceBucket, sourceKey, destBucket) {'
              - '  return new Promise((resolve, reject) => {'
              - '    var destKey = sourceKey;'
              - "    var msg = 'copying ' + sourceBucket + ':' + sourceKey + ' to ' + destBucket + ':' + destKey;"
              - ''
              - "    console.log('Attempting: ' + msg);"
              - '    s3.copyObject({'
              - '      Bucket: destBucket,'
              - '      Key: destKey,'
              - "      CopySource: encodeURIComponent(sourceBucket + '/' + sourceKey),"
              - "      MetadataDirective: 'COPY'"
              - '    }, (err, data) => {'
              - '      if (err) {'
              - "        console.log('Error:' + msg);"
              - '        console.log(err, err.stack); // an error occurred'
              - "        return reject('Error:' + msg);"
              - '      } else {'
              - "        console.log('Success: ' + msg);"
              - "        return resolve('Success: ' + msg);"
              - '      }'
              - '    });'
              - '  });'
              - '}'
              - ''
              - 'function sleep(ms){'
              - '    return new Promise(resolve=>{'
              - '        setTimeout(resolve,ms)'
              - '    })'
              - '}'
      Description: Makes sure the input artifacts are in the right bucket.
      FunctionName: CrossAccountPipelineSyncArtifacts
      Handler: index.handler
      MemorySize: 128
      Role: !GetAtt SyncArtifactsRole.Arn
      Runtime: nodejs10.x
      Timeout: 30

  # Basic permissions to allow CodePipeline to call the sync function.
  SyncArtifactsLambdaPermission:
    Type: 'AWS::Lambda::Permission'
    Properties:
      Action: 'lambda:InvokeFunction'
      FunctionName: !Ref SyncArtifactsFunction
      Principal: codepipeline.amazonaws.com
      SourceAccount: !Ref 'AWS::AccountId'
      SourceArn: !Sub 'arn:aws:codepipeline:${AWS::Region}:${AWS::AccountId}:*'

  # Role for the replication function.
  ReplicationRole:
    Type: 'AWS::IAM::Role'
    Properties:
      RoleName: CrossAccountPipelineS3Replication
      AssumeRolePolicyDocument:
        Version: '2012-10-17'
        Statement:
          - Effect: Allow
            Principal:
              Service: lambda.amazonaws.com
            Action: 'sts:AssumeRole'
      ManagedPolicyArns:
        - !Ref ReplicationPolicy
        - 'arn:aws:iam::aws:policy/service-role/AWSLambdaBasicExecutionRole'

  # This policy allows the replication function to read data from the build bucket.
  ReplicationPolicy:
    Type: 'AWS::IAM::ManagedPolicy'
    Properties:
      ManagedPolicyName: CrossAccountPipelineS3Replication
      Description: Policy for replicating S3 data for developer account pipelines
      PolicyDocument:
        Version: '2012-10-17'
        Statement:
          - Action:
              - 's3:ListBucket'
            Effect: Allow
            Resource:
              - 'Fn::Sub':
                  - 'arn:aws:s3:::${Bucket}'
                  - Bucket: !ImportValue BuildBucket
          - Action:
              - 's3:Get*'
            Effect: Allow
            Resource:
              - 'Fn::Sub':
                  - 'arn:aws:s3:::${Bucket}/*'
                  - Bucket: !ImportValue BuildBucket
          - Action:
              - 'kms:Decrypt'
            Effect: Allow
            Resource: !GetAtt KMSKey.Arn

  # This function is triggered on created objects in the build bucket and copies the objects to
  # the developer accounts.
  ReplicationFunction:
    Type: 'AWS::Lambda::Function'
    Properties:
      Code:
        ZipFile:
          # Modify this function to get the bucket list from somewhere else (parameter store?)
          # This will allow the replication to always be on, and an custom resource can add
          # replication buckets to that location
          'Fn::Join':
            - |+

            - - const aws = require('aws-sdk');
              - "const s3 = new aws.S3({region: 'us-east-1'});"
              - const path = require('path');
              - ''
              - "const destBuckets = process.env.DEST_BUCKETS.split(',');"
              - ''
              - 'exports.handler = function main(event, context) {'
              - '  // Fail on mising data'
              - '  if (!destBuckets) {'
              - "    context.fail('Error: Environment variable DEST_BUCKETS missing');"
              - '    return;'
              - '  }'
              - '  if (event.Records === null) {'
              - "    context.fail('Error: Event has no records.');"
              - '    return;'
              - '  }'
              - '  // Make a task for each combination of record and destBucket'
              - '  let tasks = [];'
              - '  for (let i = 0; i < event.Records.length; i++) {'
              - '    for (let j = 0; j < destBuckets.length; j++) {'
              - '      tasks.push(replicatePromise(event.Records[i], destBuckets[j]));'
              - '    }'
              - '  }'
              - ''
              - '  Promise.all(tasks)'
              - '    .then(() => { context.succeed();'
              - '    })'
              - '    .catch(() => { context.fail();'
              - '    });'
              - '};'
              - ''
              - 'function replicatePromise(record, destBucket) {'
              - '  return new Promise((resolve, reject) => {'
              - '    // The source bucket and source key are part of the event data'
              - '    var srcBucket = record.s3.bucket.name;'
              - '    var srcKey = decodeURIComponent(record.s3.object.key.replace(/\+/g," "));'
              - '    var srcVersion = record.s3.object.version;'
              - ''
              - '    // Modify destKey if an alternate copy location is preferred'
              - '    var destKey = srcKey;'
              - "    var msg = 'copying ' + srcBucket + ':' + srcKey + ' to ' + destBucket + ':' + destKey;"
              - ''
              - "    console.log('Attempting: ' + msg);"
              - '    s3.copyObject({'
              - '      Bucket: destBucket,'
              - '      Key: destKey,'
              - "      ACL: 'bucket-owner-full-control',"
              - "      CopySource: encodeURIComponent(srcBucket + '/' + srcKey + (srcVersion ? ('?versionId=' + srcVersion) : '')),"
              - "      MetadataDirective: 'COPY'"
              - '    }, (err, data) => {'
              - '      if (err) {'
              - "        console.log('Error:' + msg);"
              - '        console.log(err, err.stack); // an error occurred'
              - "        return reject('Error:' + msg);"
              - '      }'
              - '      else {'
              - "        console.log('Success: ' + msg);"
              - "        return resolve('Success: ' + msg);"
              - '      }'
              - '    });'
              - '  });'
              - '}'
      Description: Copies data from on S3 bucket to a list of destination buckets.
      FunctionName: S3DataReplicator
      Handler: index.handler
      MemorySize: 128
      Role: !GetAtt ReplicationRole.Arn
      Runtime: nodejs10.x
      Timeout: 30

  # Basic permissions to allow the replication function to be triggered by the build bucket.
  ReplicationLambdaPermission:
    Type: 'AWS::Lambda::Permission'
    Properties:
      Action: 'lambda:InvokeFunction'
      FunctionName: !Ref ReplicationFunction
      Principal: s3.amazonaws.com
      SourceAccount: !Ref 'AWS::AccountId'
      SourceArn:
        'Fn::Sub':
          - 'arn:aws:s3:::${Bucket}'
          - Bucket: !ImportValue BuildBucket

  # This is the bucket where build artifacts are put. CodeBuild should place
  # things here, and CodePipeline should trigger off specific artifacts.
  # This bucket's artifacts will be replicated to developer accounts.
  BuildBucket:
    Type: 'AWS::S3::Bucket'
    Properties:
      PublicAccessBlockConfiguration:
        BlockPublicAcls: true
        BlockPublicPolicy: true
        IgnorePublicAcls: true
        RestrictPublicBuckets: true
      VersioningConfiguration:
        Status: Enabled
      BucketEncryption:
        ServerSideEncryptionConfiguration:
          - ServerSideEncryptionByDefault:
              KMSMasterKeyID: !GetAtt KMSKey.Arn
              SSEAlgorithm: 'aws:kms'

  # This is the bucket that is used for CodePipeline, in the primary region
  PipelineBucket:
    Type: 'AWS::S3::Bucket'
    Properties:
      PublicAccessBlockConfiguration:
        BlockPublicAcls: true
        BlockPublicPolicy: true
        IgnorePublicAcls: true
        RestrictPublicBuckets: true
      BucketEncryption:
        ServerSideEncryptionConfiguration:
          - ServerSideEncryptionByDefault:
              KMSMasterKeyID: !GetAtt KMSKey.Arn
              SSEAlgorithm: 'aws:kms'

  # Grant access to the cross account CloudFormation and CodePipeline roles within the deployment organization
  PipelineBucketPolicy:
    Type: 'AWS::S3::BucketPolicy'
    Properties:
      Bucket: !Ref PipelineBucket
      PolicyDocument:
        Statement:
          - Action:
              - 's3:*' # TODO: this doesn't need to be star
            Effect: Allow
            Resource:
              - !Sub 'arn:aws:s3:::${PipelineBucket}'
              - !Sub 'arn:aws:s3:::${PipelineBucket}/*'
            Principal: '*'
            Condition:
              ArnLike:
                aws:PrincipalArn: arn:aws:iam::*:role/CrossAccountCloudFormation
              ForAnyValue:StringLike:
                aws:PrincipalOrgPaths:
                  - !Ref DeploymentOrgPath
          - Action:
              - 's3:*' # TODO: this doesn't need to be star
            Effect: Allow
            Resource:
              - !Sub 'arn:aws:s3:::${PipelineBucket}'
              - !Sub 'arn:aws:s3:::${PipelineBucket}/*'
            Principal: '*'
            Condition:
              ArnLike:
                aws:PrincipalArn: arn:aws:iam::*:role/CrossAccountCodePipeline
              ForAnyValue:StringLike:
                aws:PrincipalOrgPaths:
                  - !Ref DeploymentOrgPath

  # This role is only to allow the custom resource for adding a bucket notification
  # to the build bucket whilst avoiding the circular reference issue.
  ApplyNotificationFunctionRole:
    Type: AWS::IAM::Role
    Properties:
      AssumeRolePolicyDocument:
        Version: '2012-10-17'
        Statement:
          - Effect: Allow
            Principal:
              Service: lambda.amazonaws.com
            Action: sts:AssumeRole
      ManagedPolicyArns:
        - arn:aws:iam::aws:policy/service-role/AWSLambdaBasicExecutionRole
      Path: /
      Policies:
        - PolicyName: S3BucketNotificationPolicy
          PolicyDocument:
            Version: '2012-10-17'
            Statement:
              - Sid: AllowBucketNotification
                Effect: Allow
                Action: s3:PutBucketNotification
                Resource:
                  - !Sub 'arn:aws:s3:::${BuildBucket}'
                  - !Sub 'arn:aws:s3:::${BuildBucket}/*'

  # This function is for adding a bucket notification to the build bucket whilst avoiding
  # the circular reference issue. It is only called during deployment of this stack.
  ApplyBucketNotificationFunction:
    Type: AWS::Lambda::Function
    Properties:
      Description: Dummy function, just logs the received event
      Handler: index.handler
      Runtime: python2.7
      Role: !GetAtt 'ApplyNotificationFunctionRole.Arn'
      Timeout: 240
      Code:
        ZipFile: |
          import boto3
          import logging
          import json
          import cfnresponse

          s3Client = boto3.client('s3')
          logger = logging.getLogger()
          logger.setLevel(logging.DEBUG)

          def addBucketNotification(bucketName, notificationId, functionArn):
            notificationResponse = s3Client.put_bucket_notification_configuration(
              Bucket=bucketName,
              NotificationConfiguration={
                'LambdaFunctionConfigurations': [
                  {
                    'Id': notificationId,
                    'LambdaFunctionArn': functionArn,
                    'Events': [
                      's3:ObjectCreated:*'
                    ]
                  },
                ]
              }
            )
            return notificationResponse

          def create(properties, physical_id):
            bucketName = properties['S3Bucket']
            notificationId = properties['NotificationId']
            functionArn = properties['FunctionARN']
            response = addBucketNotification(bucketName, notificationId, functionArn)
            logger.info('AddBucketNotification response: %s' % json.dumps(response))
            return cfnresponse.SUCCESS, physical_id

          def update(properties, physical_id):
            return cfnresponse.SUCCESS, None

          def delete(properties, physical_id):
            return cfnresponse.SUCCESS, None

          def handler(event, context):
            logger.info('Received event: %s' % json.dumps(event))

            status = cfnresponse.FAILED
            new_physical_id = None

            try:
              properties = event.get('ResourceProperties')
              physical_id = event.get('PhysicalResourceId')

              status, new_physical_id = {
                'Create': create,
                'Update': update,
                'Delete': delete
              }.get(event['RequestType'], lambda x, y: (cfnresponse.FAILED, None))(properties, physical_id)
            except Exception as e:
              logger.error('Exception: %s' % e)
              status = cfnresponse.FAILED
            finally:
              cfnresponse.send(event, context, status, {}, new_physical_id)

  # This custom resource creates the notification on the build bucket so that we can
  # trigger a lambda whenever something is created in the build bucket.
  # This is a custom resource because of the circular reference issue that is caused
  # by trying to do this inline.
  ApplyNotification:
    Type: Custom::ApplyNotification
    Properties:
      ServiceToken: !GetAtt 'ApplyBucketNotificationFunction.Arn'
      S3Bucket: !Ref BuildBucket
      FunctionARN: !GetAtt ReplicationFunction.Arn
      NotificationId: S3ObjectCreatedEvent

Outputs:
  CMK:
    Description: The CMK that is used for cross account access
    Value: !GetAtt KMSKey.Arn
    Export:
      Name: CrossAccountCMK
  BuildBucket:
    Description: The bucket for the builds
    Value: !Ref BuildBucket
    Export:
      Name: BuildBucket
  PipelineBucket:
    Description: The bucket for the pipeline
    Value: !Ref PipelineBucket
    Export:
      Name: PipelineBucket
  SyncArtifactsFunction:
    Description: The function for syncing artifacts
    Value: !Ref SyncArtifactsFunction
    Export:
      Name: SyncArtifactsFunction
  SyncArtifactsFunctionArn:
    Description: The function for syncing artifacts
    Value: !GetAtt SyncArtifactsFunction.Arn
    Export:
      Name: SyncArtifactsFunctionArn
  ReplicationFunctionArn:
    Description: The function for replication build artifacts
    Value: !GetAtt ReplicationFunction.Arn
    Export:
      Name: ReplicationFunctionArn
  ReplicationRoleArn:
    Description: The role used for replication.
    Value: !GetAtt ReplicationRole.Arn
  ApplyBucketNotificationFunctionArn:
    Description: The ARN of the function to apply a bucket notification to the build bucket
    Value: !GetAtt ApplyBucketNotificationFunction.Arn
    Export:
      Name: ApplyBucketNotificationFunctionArn
